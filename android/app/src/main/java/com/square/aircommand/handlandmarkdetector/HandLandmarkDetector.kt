package com.square.aircommand.handlandmarkdetector

import android.content.Context
import android.graphics.Bitmap
import android.util.Log
import androidx.compose.runtime.mutableStateListOf
import com.square.aircommand.tflite.AIHubDefaults
import com.square.aircommand.tflite.TFLiteHelpers
import com.square.aircommand.ui.theme.listener.TrainingProgressListener
import com.square.aircommand.utils.ModelStorageManager
import com.square.aircommand.utils.ModelStorageManager.getSavedModelCode
import com.square.aircommand.utils.ModelStorageManager.saveModelCode
import com.square.aircommand.utils.ModelStorageManager.updateLabelMap
import com.square.aircommand.utils.ThrottledLogger
import okhttp3.*
import okhttp3.MediaType.Companion.toMediaTypeOrNull
import org.json.JSONArray
import org.json.JSONObject
import org.opencv.android.Utils
import org.opencv.core.*
import org.opencv.imgproc.Imgproc
import org.opencv.osgi.OpenCVNativeLoader
import org.tensorflow.lite.Delegate
import org.tensorflow.lite.Interpreter
import java.io.File
import java.io.IOException
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.util.concurrent.TimeUnit

class HandLandmarkDetector(
    private val context: Context,
    modelPath: String,
    delegatePriorityOrder: Array<Array<TFLiteHelpers.DelegateType>>,
    private var progressListener: TrainingProgressListener? = null
) : AutoCloseable {

    private val interpreter: Interpreter
    private val delegateStore: Map<TFLiteHelpers.DelegateType, Delegate>

    val inputWidth: Int
    val inputHeight: Int
    var isCollecting: Boolean = true
        private set

    private val inputBuffer: ByteBuffer
    private val inputFloatArray: FloatArray
    private val inputMatAbgr: Mat
    private val inputMatRgb: Mat
    private val landmarkSequence = mutableListOf<List<Triple<Double, Double, Double>>>()
    private val _landmarkSequence = mutableStateListOf<List<Triple<Double, Double, Double>>>()
    private var frameCounter = 0
    private val frameInterval = 3
    private val client = OkHttpClient.Builder()
        .connectTimeout(30, TimeUnit.SECONDS) // ì„œë²„ ì—°ê²° íƒ€ì„ì•„ì›ƒ
        .readTimeout(30, TimeUnit.SECONDS)    // ì‘ë‹µ ëŒ€ê¸° íƒ€ì„ì•„ì›ƒ
        .writeTimeout(30, TimeUnit.SECONDS)   // ìš”ì²­ ì „ì†¡ íƒ€ì„ì•„ì›ƒ
        .build()

    val lastLandmarks = mutableListOf<Triple<Double, Double, Double>>()
    var lastHandedness: String = "Left" // ì›ë˜ Rightì„
    private var isReadyToSend = false
    private var savedGestureName: String? = null
    var percent = 0

    init {
        OpenCVNativeLoader().init()

        val (modelBuffer, hash) = TFLiteHelpers.loadModelFile(context.assets, modelPath)
        val (i, delegates) = TFLiteHelpers.createInterpreterAndDelegatesFromOptions(
            modelBuffer, delegatePriorityOrder,
            AIHubDefaults.numCPUThreads,
            context.applicationInfo.nativeLibraryDir,
            context.cacheDir.absolutePath, hash
        )
        interpreter = i
        delegateStore = delegates

        val inputShape = interpreter.getInputTensor(0).shape()
        inputHeight = inputShape[1]
        inputWidth = inputShape[2]

        inputFloatArray = FloatArray(inputHeight * inputWidth * 3)
        inputBuffer = ByteBuffer.allocateDirect(4 * inputFloatArray.size).order(ByteOrder.nativeOrder())
        inputMatAbgr = Mat(inputHeight, inputWidth, CvType.CV_8UC4)
        inputMatRgb = Mat(inputHeight, inputWidth, CvType.CV_8UC3)
    }

    override fun close() {
        interpreter.close()
        delegateStore.values.forEach { it.close() }
    }

    fun predict(image: Bitmap, sensorOrientation: Int): Bitmap {
        preprocessImage(image, sensorOrientation)

        val (landmarks, score, handedness) = runInference()

        lastLandmarks.clear()
        if (score < 0.005f) {
            return image
        }

        lastHandedness = if (handedness > 0.5f) "Right" else "Left"
        extractLandmarks(landmarks)
        drawLandmarks(image.width, image.height)

        return convertMatToBitmap(image)
    }

    fun sendToServerIfReady(context: Context, onFinished: () -> Unit) {
        if (!isReadyToSend || savedGestureName == null || _landmarkSequence.size != 100) {
            Log.w("HandLandmarkDetector", "â— ì €ì¥ ì¡°ê±´ ë¶ˆì¶©ë¶„ - ì„œë²„ì— ì „ì†¡í•˜ì§€ ì•ŠìŒ")
            return
        }

        val modelCode = getSavedModelCode(context)
        progressListener?.onTrainingStarted()

        sendTrainData(
            modelCode = modelCode,
            gesture = savedGestureName!!,
            landmarkSequence = _landmarkSequence
        ) { newModelCode, modelUrl ->
            // 1) ëª¨ë¸ ì½”ë“œ ì €ì¥
            saveModelCode(context, newModelCode)

            // 2) ë¼ë²¨ ì €ì¥
            updateLabelMap(context, savedGestureName!!)

            // 3) model_url.json ìƒì„±
            val modelUrlFile = File(context.filesDir, "model_url.json")
            modelUrlFile.writeText(JSONObject().put("model_url", modelUrl).toString())

            // 4) ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° êµì²´
            progressListener?.onModelDownloadStarted()
            ModelStorageManager.downloadAndReplaceModel(context)
            progressListener?.onModelDownloadComplete()

            Log.d("HandLandmarkDetector", "âœ… ì„œë²„ ì „ì†¡ ë° ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ")

            // ìƒíƒœ ì´ˆê¸°í™”
            isReadyToSend = false
            savedGestureName = null
            _landmarkSequence.clear()
        }
    }

//    fun retryLastSend(name: String) {
//        if (_landmarkSequence.size == 100) {
//            savedGestureName = name
//            isReadyToSend = true
//            Log.d("HandLandmarkDetector", "âœ… ì¬ì‹œë„ ì¤€ë¹„ ì™„ë£Œ")
//        } else {
//            Log.w("HandLandmarkDetector", "âš ï¸ ì¬ì‹œë„ ë¶ˆê°€: landmarkSequence ë¶€ì¡±")
//        }
//    }




    fun resetCollection() {
        _landmarkSequence.clear()
        frameCounter = 0
        isReadyToSend = false
        savedGestureName = ""
        isCollecting = true
        progressListener?.onCollectionProgress(0)
        Log.d("HandLandmarkDetector", "ğŸ”„ ëœë“œë§ˆí¬ ìˆ˜ì§‘ ìƒíƒœ ì´ˆê¸°í™”ë¨")
    }

    fun transfer(
        image: Bitmap,
        sensorOrientation: Int,
        gestureName: String,
        trainingProgressListener: TrainingProgressListener?
    ): Bitmap {

        progressListener = trainingProgressListener

        if (!isCollecting) {
            ThrottledLogger.log("HandLandmarkDetector", "â¸ï¸ í˜„ì¬ ìˆ˜ì§‘ ì¤‘ì´ ì•„ë‹˜ (isCollecting = false)")
            return image
        }

        preprocessImage(image, sensorOrientation)
        val (landmarks, score, handedness) = runInference()

        lastLandmarks.clear()
        if (score < 0.005f) {
            ThrottledLogger.log("HandLandmarkDetector", "âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì ìˆ˜ ($score)")
            return image
        }

        lastHandedness = if (handedness > 0.5f) "Right" else "Left"
        extractLandmarks(landmarks)

        if (_landmarkSequence.size < 100) {
            if (frameCounter % frameInterval == 0) {
                extract63Landmarks(landmarks, image.width, image.height)
                percent = (_landmarkSequence.size * 100) / 100
                Log.d("HandLandmarkDetector", "ëœë“œë§ˆí¬ ìˆ˜ì§‘ ì¤‘ (ì´ ${_landmarkSequence.size})")
                progressListener?.onCollectionProgress(percent) // ğŸ‘ˆ ì½œë°± í˜¸ì¶œ
            }
            frameCounter++
        }

        if (_landmarkSequence.size == 100) {
            isReadyToSend = true
            savedGestureName = gestureName
            stopCollecting()
            Log.d("HandLandmarkDetector", "ğŸ›‘ ëœë“œë§ˆí¬ ìˆ˜ì§‘ ì™„ë£Œ - ì €ì¥ ë²„íŠ¼ ëŒ€ê¸° ìƒíƒœ")
        }
        drawLandmarks(image.width, image.height)
        return convertMatToBitmap(image)
    }

    fun startCollecting() {
        isCollecting = true
        _landmarkSequence.clear()
    }

    fun stopCollecting() {
        isCollecting = false
    }

    private fun extract63Landmarks(landmarks: Array<Array<FloatArray>>, imgW: Int, imgH: Int) {
        val frameLandmarks = mutableListOf<Triple<Double, Double, Double>>()
        for (i in 0 until 21) {
            val (fx, fy, fz) = landmarks[0][i]
            frameLandmarks.add(Triple(fx.toDouble(), fy.toDouble(), fz.toDouble()))
        }
        _landmarkSequence.add(frameLandmarks)
    }

    private fun preprocessImage(image: Bitmap, sensorOrientation: Int) {
        Utils.bitmapToMat(image, inputMatAbgr)
        Imgproc.cvtColor(inputMatAbgr, inputMatRgb, Imgproc.COLOR_BGRA2RGB)

        when (sensorOrientation) {
            90 -> Core.rotate(inputMatRgb, inputMatRgb, Core.ROTATE_90_CLOCKWISE)
            180 -> Core.rotate(inputMatRgb, inputMatRgb, Core.ROTATE_180)
            270 -> Core.rotate(inputMatRgb, inputMatRgb, Core.ROTATE_90_COUNTERCLOCKWISE)
        }

        val resizedInputMat = Mat()
        Imgproc.resize(inputMatRgb, resizedInputMat, Size(inputWidth.toDouble(), inputHeight.toDouble()))

        resizedInputMat.convertTo(resizedInputMat, CvType.CV_32FC3, 1.0 / 255.0)
        resizedInputMat.get(0, 0, inputFloatArray)

        inputBuffer.rewind()
        inputBuffer.asFloatBuffer().put(inputFloatArray)

    }

    private fun runInference(): Triple<Array<Array<FloatArray>>, Float, Float> {
        val outputLandmarks = Array(1) { Array(21) { FloatArray(3) } }
        val outputScores = FloatArray(1)
        val outputLR = FloatArray(1)

        val outputMap = mutableMapOf<Int, Any>().apply {
            for (i in 0 until interpreter.outputTensorCount) {
                when (interpreter.getOutputTensor(i).name()) {
                    "landmarks" -> put(i, outputLandmarks)
                    "scores" -> put(i, outputScores)
                    "lr" -> put(i, outputLR)
                }
            }
        }

        interpreter.runForMultipleInputsOutputs(arrayOf(inputBuffer), outputMap)

        return Triple(outputLandmarks, outputScores[0], outputLR[0])
    }

    private fun extractLandmarks(landmarks: Array<Array<FloatArray>>) {
        for (i in 0 until 21) {
            val (fx, fy, fz) = landmarks[0][i]
            lastLandmarks.add(Triple(fx.toDouble(), fy.toDouble(), fz.toDouble()))
        }
    }

    private fun drawLandmarks(imgW: Int, imgH: Int) {
        lastLandmarks.forEachIndexed { idx, (x, y, _) ->
            val px = (x * imgW).toInt().coerceIn(0, imgW - 1)
            val py = (y * imgH).toInt().coerceIn(0, imgH - 1)
            Imgproc.circle(inputMatRgb, Point(px.toDouble(), py.toDouble()), 5, Scalar(0.0, 255.0, 0.0), -1)
        }
    }

    private fun convertMatToBitmap(original: Bitmap): Bitmap {
        val matW = inputMatRgb.cols()
        val matH = inputMatRgb.rows()

        if (matW <= 0 || matH <= 0) {
            Log.e("LandmarkDetector", "ì˜ëª»ëœ ì´ë¯¸ì§€ í¬ê¸°")
            return original
        }

        val outputBitmap = Bitmap.createBitmap(matW, matH, Bitmap.Config.ARGB_8888)
        Imgproc.cvtColor(inputMatRgb, inputMatAbgr, Imgproc.COLOR_RGB2BGRA)

        return try {
            Utils.matToBitmap(inputMatAbgr, outputBitmap)
            outputBitmap
        } catch (e: CvException) {

            Log.e("LandmarkDetector", "matToBitmap ì‹¤íŒ¨: ${e.message}", e)
            original
        }
    }

    fun sendTrainData(
        modelCode: String,
        gesture: String,
        landmarkSequence: MutableList<List<Triple<Double, Double, Double>>>,
        onSuccess: (newModelCode: String, modelUrl: String) -> Unit,
    ) {
        val landmarksJsonArray = JSONArray()
        for (frame in landmarkSequence) {
            val frameArray = JSONArray()
            frame.forEach { (x, y, z) ->
                frameArray.put(JSONArray(listOf(x, y, z)))
            }
            landmarksJsonArray.put(frameArray)
        }

        val json = JSONObject().apply {
            put("model_code", modelCode)
            put("gesture", gesture)
            put("landmarks", landmarksJsonArray)
        }

        val body = RequestBody.create(
            "application/json; charset=utf-8".toMediaTypeOrNull(),
            json.toString()
        )

        val request = Request.Builder()
            .url("http://13.125.161.99:8000/train_model/")
            .post(body)
            .build()

        client.newCall(request).enqueue(object : Callback {
            override fun onFailure(call: Call, e: IOException) {
                progressListener?.fail()
                println("ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: ${e.message}")
            }

            override fun onResponse(call: Call, response: Response) {
                if (response.isSuccessful) {
                    val bodyStr = response.body?.string() ?: "{}"
                    val resultJson = JSONObject(bodyStr)

                    val modelCode = resultJson.optString("new_model_code", "basic")
                    val modelUrl = resultJson.optString("new_tflite_model_url", "")

                    // ì½œë°±ì— ì „ë‹¬
                    onSuccess(modelCode, modelUrl)
                } else {
                    println("ì‘ë‹µ ì˜¤ë¥˜ ì½”ë“œ: ${response.code}")
                }
            }
        })
    }
}

