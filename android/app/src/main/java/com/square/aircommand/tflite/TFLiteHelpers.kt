package com.square.aircommand.tflite

import android.content.res.AssetManager
import android.util.Log
import com.qualcomm.qti.QnnDelegate
import org.tensorflow.lite.Delegate
import org.tensorflow.lite.Interpreter
import org.tensorflow.lite.gpu.GpuDelegate
import org.tensorflow.lite.gpu.GpuDelegateFactory
import java.io.FileInputStream
import java.io.IOException
import java.nio.MappedByteBuffer
import java.nio.channels.FileChannel
import java.security.DigestInputStream
import java.security.MessageDigest
import java.security.NoSuchAlgorithmException

object TFLiteHelpers {
    private const val TAG = "QualcommTFLiteHelpers"

    // Delegate íƒ€ì…ì„ ì •ì˜í•¨
    enum class DelegateType {
        GPUv2,
        QNN_NPU_FP16,
        QNN_NPU_QUANTIZED
    }

    // delegate ìš°ì„ ìˆœìœ„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ interpreterì™€ delegateë“¤ì„ ìƒì„±í•¨
    fun CreateInterpreterAndDelegatesFromOptions(
        tfLiteModel: MappedByteBuffer,
        delegatePriorityOrder: Array<Array<DelegateType>>,
        numCPUThreads: Int,
        nativeLibraryDir: String,
        cacheDir: String,
        modelIdentifier: String
    ): Pair<Interpreter, Map<DelegateType, Delegate>> {
        val delegates = mutableMapOf<DelegateType, Delegate>()
        val modelCachePath = "$cacheDir/$modelIdentifier.htp_cache"
        val cacheFile = java.io.File(modelCachePath)
        if (cacheFile.exists()) {
            Log.w(TAG, "âš ï¸ QNN ìºì‹œ ì¡´ì¬í•¨: $modelCachePath â†’ ì‚­ì œ í›„ ì¬ìƒì„± ì‹œë„")
            cacheFile.delete()
        }
        val attemptedDelegates = mutableSetOf<DelegateType>()

        // delegate ì¡°í•©ë³„ë¡œ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„í•¨
        for (delegatesToRegister in delegatePriorityOrder) {
            // ì´ë¯¸ ì‹œë„í•œ delegateëŠ” ê±´ë„ˆëœ€
            delegatesToRegister.filterNot { attemptedDelegates.contains(it) }.forEach { type ->
                CreateDelegate(type, nativeLibraryDir, cacheDir, modelIdentifier)?.let {
                    delegates[type] = it
                }
                attemptedDelegates.add(type)
            }

            // ì´ ì¡°í•©ì˜ ëª¨ë“  delegateê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°
            if (delegatesToRegister.any { !delegates.containsKey(it) }) continue

            // interpreter ìƒì„± ì‹œë„í•¨
            val pairs = delegatesToRegister.map { Pair(it, delegates[it]) }.toTypedArray()
            val interpreter = CreateInterpreterFromDelegates(pairs, numCPUThreads, tfLiteModel) ?: continue

            // ì‚¬ìš©í•˜ì§€ ì•Šì€ delegateëŠ” í•´ì œí•¨
            val used = delegatesToRegister.toSet()
            delegates.keys.filterNot { it in used }.forEach {
                delegates.remove(it)?.close()
            }

            return Pair(interpreter, delegates)
        }

        // ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒì‹œí‚´
        throw RuntimeException("Unable to create interpreter with any delegate combination.")
    }

    // ì£¼ì–´ì§„ delegate ë°°ì—´ë¡œ interpreterë¥¼ ìƒì„±í•¨
    fun CreateInterpreterFromDelegates(
        delegates: Array<Pair<DelegateType, Delegate?>>, numCPUThreads: Int, tfLiteModel: MappedByteBuffer
    ): Interpreter? {
        val options = Interpreter.Options().apply {
            setAllowBufferHandleOutput(true)
            setUseNNAPI(false)
            setNumThreads(numCPUThreads)
            setUseXNNPACK(true) // CPU fallback ëŒ€ë¹„

            // ê° delegateë¥¼ optionsì— ì¶”ê°€í•¨
            delegates.forEach { (type, delegate) ->
                if (delegate != null) {
                    Log.i(TAG, "âœ… [$type] delegateê°€ ì •ìƒì ìœ¼ë¡œ ì¶”ê°€ë¨")

                    addDelegate(delegate)
                } else {
                    Log.w(TAG, "âš ï¸ [$type] delegateê°€ nullì´ë¼ ì¶”ê°€ë˜ì§€ ì•ŠìŒ")
                }
            }
        }
        val enabledList = delegates.map { it.first.name }
        Log.i(TAG, "ğŸ§© ì‹œë„ëœ delegate ì¡°í•©: ${enabledList.joinToString(" + ")}")

        return try {
            Interpreter(tfLiteModel, options).apply {
                allocateTensors()
                // ğŸ“¥ ì…ë ¥ í…ì„œ ì •ë³´ ë¡œê·¸
                for (i in 0 until inputTensorCount) {
                    val t = getInputTensor(i)
                    Log.i(TAG, "ğŸ“¥ ì…ë ¥[$i] name=${t.name()}, dtype=${t.dataType()}, shape=${t.shape().contentToString()}")
                }

                // ğŸ“¤ ì¶œë ¥ í…ì„œ ì •ë³´ ë¡œê·¸
                for (i in 0 until outputTensorCount) {
                    val t = getOutputTensor(i)
                    Log.i(TAG, "ğŸ“¤ ì¶œë ¥[$i] name=${t.name()}, dtype=${t.dataType()}, shape=${t.shape().contentToString()}")
                }
                Log.i(TAG, "ğŸ¯ Interpreter ìƒì„± ì„±ê³µí•¨. ì‚¬ìš©ëœ delegate: ${
                    delegates.map { it.first }.joinToString(", ")
                }")
            }
        } catch (e: Exception) {
            val enabledDelegates = delegates.map { it.first.name }.toMutableList().apply { add("XNNPack") }
            Log.w(TAG, "âš ï¸ ëª¨ë“  delegate ì‹¤íŒ¨. XNNPack (CPU fallback) ì‚¬ìš© ê°€ëŠ¥ì„± ìˆìŒ.")
            Log.e(TAG, "âŒ Interpreter ìƒì„± ì‹¤íŒ¨í•¨. ì‹œë„ëœ delegate: ${enabledDelegates.joinToString(", ")} | ì˜¤ë¥˜: ${e.message}")
            null
        }
    }

    // assets í´ë”ì—ì„œ ëª¨ë¸ íŒŒì¼ì„ ì½ê³  MD5 í•´ì‹œê°’ì„ ë°˜í™˜í•¨
    @Throws(IOException::class, NoSuchAlgorithmException::class)
    fun loadModelFile(assets: AssetManager, modelFilename: String): Pair<MappedByteBuffer, String> {
        val fileDescriptor = assets.openFd(modelFilename)
        val buffer: MappedByteBuffer
        val hash: String

        FileInputStream(fileDescriptor.fileDescriptor).use { inputStream ->
            val channel = inputStream.channel
            val startOffset = fileDescriptor.startOffset
            val declaredLength = fileDescriptor.declaredLength
            buffer = channel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength)

            // ëª¨ë¸ì˜ MD5 í•´ì‹œë¥¼ ê³„ì‚°í•¨
            val digest = MessageDigest.getInstance("MD5")
            inputStream.skip(startOffset)
            DigestInputStream(inputStream, digest).use { dis ->
                val data = ByteArray(8192)
                var totalRead = 0
                while (totalRead < declaredLength) {
                    val bytesRead = dis.read(data, 0, minOf(8192, (declaredLength - totalRead).toInt()))
                    if (bytesRead == -1) break
                    totalRead += bytesRead
                }
            }
            hash = digest.digest().joinToString("") { "%02x".format(it) }
        }
        Log.i(TAG, "ğŸ“¦ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ - íŒŒì¼ëª…: $modelFilename | MD5 í•´ì‹œ: $hash")
        return Pair(buffer, hash)
    }

    // delegate íƒ€ì…ì— ë”°ë¼ í•´ë‹¹ delegateë¥¼ ìƒì„±í•¨
    private fun CreateDelegate(
        delegateType: DelegateType,
        nativeLibraryDir: String,
        cacheDir: String,
        modelIdentifier: String
    ): Delegate? {
        return when (delegateType) {
            DelegateType.GPUv2 -> {
                val d = CreateGPUv2Delegate(cacheDir, modelIdentifier)
                if (d != null) Log.i(TAG, "âœ… GPUv2 delegate ìƒì„± ì™„ë£Œ") else Log.w(TAG, "âš ï¸ GPUv2 delegate ìƒì„± ì‹¤íŒ¨")
                d
            }
            DelegateType.QNN_NPU_FP16 -> {
                val d = CreateQNN_NPUDelegate(nativeLibraryDir, cacheDir, modelIdentifier, true)
                if (d != null) Log.i(TAG, "âœ… QNN_NPU_FP16 delegate ìƒì„± ì™„ë£Œ") else Log.w(TAG, "âš ï¸ QNN_NPU_FP16 delegate ìƒì„± ì‹¤íŒ¨")
                d
            }
            DelegateType.QNN_NPU_QUANTIZED -> {
                val d = CreateQNN_NPUDelegate(nativeLibraryDir, cacheDir, modelIdentifier, false)
                if (d != null) Log.i(TAG, "âœ… QNN_NPU_QUANTIZED delegate ìƒì„± ì™„ë£Œ") else Log.w(TAG, "âš ï¸ QNN_NPU_QUANTIZED delegate ìƒì„± ì‹¤íŒ¨")
                d
            }
        }
    }

    private fun CreateQNN_NPUDelegate(
        nativeLibraryDir: String,
        cacheDir: String,
        modelIdentifier: String,
        useFP16: Boolean // âœ… ìƒˆ ì¸ì
    ): Delegate? {
        val options = QnnDelegate.Options().apply {
            setSkelLibraryDir(nativeLibraryDir)
            setLogLevel(QnnDelegate.Options.LogLevel.LOG_LEVEL_WARN)
            setCacheDir(cacheDir)
            setModelToken(modelIdentifier)

            val hasFP16 = QnnDelegate.checkCapability(QnnDelegate.Capability.HTP_RUNTIME_FP16)
            val hasQuant = QnnDelegate.checkCapability(QnnDelegate.Capability.HTP_RUNTIME_QUANTIZED)

            Log.i(TAG, "ğŸ” QNN Delegate í™œì„±í™” ì—¬ë¶€ - HTP_FP16: $hasFP16, HTP_QUANTIZED: $hasQuant")

            setBackendType(QnnDelegate.Options.BackendType.HTP_BACKEND)
            setHtpUseConvHmx(QnnDelegate.Options.HtpUseConvHmx.HTP_CONV_HMX_ON)
            setHtpPerformanceMode(QnnDelegate.Options.HtpPerformanceMode.HTP_PERFORMANCE_BURST)

            if (useFP16) {
                if (!hasFP16) {
                    Log.e(TAG, "âŒ FP16 delegate ì‚¬ìš© ìš”ì²­í–ˆì§€ë§Œ ë””ë°”ì´ìŠ¤ì—ì„œ ì§€ì›í•˜ì§€ ì•ŠìŒ")
                    return null
                }
                setHtpPrecision(QnnDelegate.Options.HtpPrecision.HTP_PRECISION_FP16)
                Log.i(TAG, "âš™ï¸ QNN Delegate ì„¤ì •: FP16 precision ëª¨ë“œ ì‚¬ìš©")
            } else {
                if (!hasQuant) {
                    Log.e(TAG, "âŒ Quantized delegate ì‚¬ìš© ìš”ì²­í–ˆì§€ë§Œ ë””ë°”ì´ìŠ¤ì—ì„œ ì§€ì›í•˜ì§€ ì•ŠìŒ")
                    return null
                }
                // setHtpPrecision ìƒëµ ì‹œ INT8ì´ ê¸°ë³¸ ì ìš©ë¨
                Log.i(TAG, "âš™ï¸ QNN Delegate ì„¤ì •: Quantized precision (INT8) ëª¨ë“œ ì‚¬ìš©")
            }

            Log.i(TAG, "âœ… QNN HTP Delegate ì˜µì…˜ ì„¤ì • ì™„ë£Œ")
        }

        return try {
            QnnDelegate(options)
        } catch (e: Exception) {
            Log.e(TAG, "QNN delegate ìƒì„± ì‹¤íŒ¨í•¨: ${e.message}")
            null
        }
    }


    // GPUv2 delegateë¥¼ ìƒì„±í•¨
    private fun CreateGPUv2Delegate(cacheDir: String, modelIdentifier: String): Delegate? {
        val options = GpuDelegateFactory.Options().apply {
            inferencePreference = GpuDelegateFactory.Options.INFERENCE_PREFERENCE_SUSTAINED_SPEED
            isPrecisionLossAllowed = true
            setSerializationParams(cacheDir, modelIdentifier)
        }

        return try {
            GpuDelegate(options)
        } catch (e: Exception) {
            Log.e(TAG, "GPUv2 delegate ìƒì„± ì‹¤íŒ¨í•¨: ${e.message}")
            null
        }
    }

    fun getModelInputType(tfLiteModel: MappedByteBuffer): org.tensorflow.lite.DataType {
        return try {
            val interpreter = Interpreter(tfLiteModel)
            val inputTensor = interpreter.getInputTensor(0)
            val inputType = inputTensor.dataType()
            interpreter.close()
            inputType
        } catch (e: Exception) {
            Log.e(TAG, "âŒ ì…ë ¥ íƒ€ì… í™•ì¸ ì‹¤íŒ¨: ${e.message}")
            org.tensorflow.lite.DataType.FLOAT32 // ê¸°ë³¸ê°’ fallback
        }
    }

    fun getDelegatePriorityOrderFromInputType(inputType: org.tensorflow.lite.DataType): Array<Array<DelegateType>> {
        return when (inputType) {
            org.tensorflow.lite.DataType.FLOAT32 -> arrayOf(
                arrayOf(DelegateType.QNN_NPU_FP16, DelegateType.GPUv2),
                arrayOf(DelegateType.GPUv2),
                arrayOf()
            )
            org.tensorflow.lite.DataType.UINT8 -> arrayOf(
                arrayOf(DelegateType.QNN_NPU_QUANTIZED, DelegateType.GPUv2),
                arrayOf(DelegateType.GPUv2),
                arrayOf()
            )
            else -> {
                Log.w(TAG, "âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì…ë ¥ íƒ€ì… $inputType, fallback to CPU")
                arrayOf()
            }
        }
    }

}